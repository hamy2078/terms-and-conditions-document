{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyj/anaconda3/envs/bert/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from model import DNN\n",
    "from dataloader import DNNDataset\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'EPOCHS':2,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':45,\n",
    "    'DATA_PATH': '../../make_data/preprocessed_data/good_bad_df.csv',\n",
    "    'SAVE_PATH':'../Models/TF-IDF_Sentence.pt',\n",
    "    'MAX_FEATURES':15000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(params['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fc48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(params['DATA_PATH'],index_col=[0])\n",
    "\n",
    "data.loc[data['ad_label']==1,'ad_label']=0\n",
    "data.loc[data['ad_label']==2,'ad_label']=1\n",
    "\n",
    "train_data, test_data = train_test_split(data,test_size=0.2,random_state=params['SEED'],shuffle=True)\n",
    "valid_data, test_data = train_test_split(test_data,test_size=0.5,random_state=params['SEED'],shuffle=True)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "valid_data = valid_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "valid_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e8ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6867\n",
      "6867\n",
      "858\n",
      "858\n",
      "859\n",
      "859\n",
      "0    0.696665\n",
      "1    0.303335\n",
      "Name: ad_label, dtype: float64\n",
      "0    0.715618\n",
      "1    0.284382\n",
      "Name: ad_label, dtype: float64\n",
      "0    0.704307\n",
      "1    0.295693\n",
      "Name: ad_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(len(valid_data))\n",
    "print(len(valid_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(train_data['ad_label'].value_counts()/len(train_data))\n",
    "print(valid_data['ad_label'].value_counts()/len(valid_data))\n",
    "print(test_data['ad_label'].value_counts()/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d3a3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=15000, ngram_range=(1, 2), sublinear_tf=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 2), max_features=params['MAX_FEATURES'], binary=False)\n",
    "tfidf.fit(train_data['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5165289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DNNDataset(train_data,tfidf)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=params['BATCH_SIZE'])\n",
    "\n",
    "valid_dataset = DNNDataset(valid_data,tfidf)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=params['BATCH_SIZE'])\n",
    "\n",
    "test_dataset = DNNDataset(test_data,tfidf)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=params['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8825aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,valid_loader, device):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=params['LEARNING_RATE'])\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = \"None\"\n",
    "    for epoch_num in range(1,params[\"EPOCHS\"]+1):\n",
    "        \n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        timings=np.zeros((len(train_loader),1))\n",
    "        cnt = 0\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = []\n",
    "        for data in tqdm(train_loader):\n",
    "            \n",
    "            starter.record()\n",
    "            \n",
    "            train_texts = data['text']\n",
    "            train_labels = data['label']\n",
    "            train_label = train_labels.to(device)\n",
    "            train_text = train_texts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(train_text)  \n",
    "            \n",
    "            output = output.reshape(-1)\n",
    "            batch_loss = criterion(output.to(torch.float32), train_label.to(torch.float32)) \n",
    "            train_loss.append(batch_loss.item())\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[cnt] = curr_time\n",
    "            cnt += 1\n",
    "        val_loss, val_acc, val_f1 = validation(model, criterion, valid_loader, device)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        print(f'Epoch [{epoch_num}], Train Loss : [{np.mean(train_loss) :.5f}] \\\n",
    "              Val Loss : [{np.mean(val_loss) :.5f}] Val Accuracy Score : [{val_acc:.5f}] Val F1 Score : [{val_f1:.5f}]')\n",
    "        print('time per batch',np.mean(timings))\n",
    "        val_score = val_f1\n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc62d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return accuracy_score(true,pred),f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation(model,criterion,valid_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    model_preds = []\n",
    "    true_labels = []  \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader):\n",
    "            \n",
    "            valid_texts = data['text']\n",
    "            valid_labels = data['label']\n",
    "          \n",
    "            valid_label = valid_labels.to(device)\n",
    "            valid_text = valid_texts.to(device)\n",
    "\n",
    "            output = model(valid_text)    \n",
    "            \n",
    "            output = output.reshape(-1)\n",
    "            batch_loss = criterion(output.to(torch.float32), valid_label.to(torch.float32)) \n",
    "            val_loss.append(batch_loss.item())\n",
    "            \n",
    "            output[output>0.5] = 1\n",
    "            output[output<=0.5] = 0\n",
    "            model_preds += output.detach().cpu().numpy().tolist()\n",
    "            true_labels += valid_label.detach().cpu().numpy().tolist()\n",
    "        val_acc, val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return val_loss, val_acc, val_f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5109bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    \n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    timings=np.zeros((len(test_loader),1))\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        rep = 0\n",
    "        for data in tqdm(test_loader):\n",
    "            starter.record()\n",
    "            \n",
    "            test_texts = data['text']\n",
    "            test_text = test_texts.to(device)\n",
    "\n",
    "            output = model(test_text)    \n",
    "            \n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "            rep += 1\n",
    "            \n",
    "            output[output>0.5] = 1\n",
    "            output[output<=0.5] = 0\n",
    "            test_predict += output.detach().cpu().numpy().tolist()\n",
    "    test_predict = torch.Tensor(test_predict)\n",
    "    test_predict = test_predict.reshape(-1)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    print('Done.')\n",
    "    \n",
    "    print('time per batch',np.mean(timings))\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b624963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:10<00:00, 41.52it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 425.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.15018]               Val Loss : [0.06831] Val Accuracy Score : [0.97669] Val F1 Score : [0.97122]\n",
      "time per batch 22.59809587168139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:09<00:00, 43.80it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 431.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.02572]               Val Loss : [0.07732] Val Accuracy Score : [0.98019] Val F1 Score : [0.97557]\n",
      "time per batch 21.385485804358193\n"
     ]
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.eval()\n",
    "\n",
    "infer_model = train(model, train_dataloader, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a1a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 428.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "time per batch 0.9949250353707207\n",
      "(0.9837019790454016, 0.9803904303473825)\n",
      "[[599   6]\n",
      " [  8 246]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = test_data['ad_label']\n",
    "test_preds = inference(infer_model,test_dataloader,device)\n",
    "\n",
    "print(competition_metric(test_labels,test_preds))\n",
    "\n",
    "print(confusion_matrix(test_labels,test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44565023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 429.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "time per batch 1.0038151089791898\n",
      "(0.9801864801864801, 0.9755692714832463)\n",
      "[[607   7]\n",
      " [ 10 234]]\n"
     ]
    }
   ],
   "source": [
    "valid_labels = valid_data['ad_label']\n",
    "valid_preds = inference(infer_model,valid_dataloader,device)\n",
    "\n",
    "print(competition_metric(valid_labels,valid_preds))\n",
    "\n",
    "print(confusion_matrix(valid_labels,valid_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd9b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:01<00:00, 428.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "time per batch 1.003320855040883\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data['ad_label']\n",
    "train_preds = inference(infer_model,train_dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d973f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9989806320081549, 0.998794226283158)\n",
      "[[4780    4]\n",
      " [   3 2080]]\n"
     ]
    }
   ],
   "source": [
    "print(competition_metric(train_labels,train_preds))\n",
    "\n",
    "print(confusion_matrix(train_labels,train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db59c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infer_model.state_dict(),params['SAVE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0911991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (fc1): Linear(in_features=15000, out_features=10000, bias=True)\n",
       "  (fc2): Linear(in_features=10000, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout5): Dropout(p=0.5, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80da1327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infermodel :  155196305\n"
     ]
    }
   ],
   "source": [
    "print(\"infermodel : \", sum(p.numel() for p in infer_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f55fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
