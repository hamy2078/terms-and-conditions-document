{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'EPOCHS':3,\n",
    "    'LEARNING_RATE':2e-5,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':45,\n",
    "    'DATA_PATH': '../../make_data/preprocessed_data/good_bad_df.csv',\n",
    "    'SAVE_PATH':'../Models/Glove_sentence.pt',\n",
    "    'max_length':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(params['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(params['DATA_PATH'],index_col=[0])\n",
    "\n",
    "data.loc[data['ad_label']==1,'ad_label']=0\n",
    "data.loc[data['ad_label']==2,'ad_label']=1\n",
    "\n",
    "train_data, test_data = train_test_split(data,test_size=0.2,random_state=params['SEED'],shuffle=True)\n",
    "valid_data, test_data = train_test_split(test_data,test_size=0.5,random_state=params['SEED'],shuffle=True)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "valid_data = valid_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "valid_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6867\n",
      "6867\n",
      "858\n",
      "858\n",
      "859\n",
      "859\n",
      "0    0.696665\n",
      "1    0.303335\n",
      "Name: ad_label, dtype: float64\n",
      "0    0.715618\n",
      "1    0.284382\n",
      "Name: ad_label, dtype: float64\n",
      "0    0.704307\n",
      "1    0.295693\n",
      "Name: ad_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(len(valid_data))\n",
    "print(len(valid_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_data.drop_duplicates(['summary'])))\n",
    "\n",
    "print(train_data['ad_label'].value_counts()/len(train_data))\n",
    "print(valid_data['ad_label'].value_counts()/len(valid_data))\n",
    "print(test_data['ad_label'].value_counts()/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_data['summary'])\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = t.texts_to_sequences(train_data['summary'])\n",
    "valid_docs = t.texts_to_sequences(valid_data['summary'])\n",
    "test_docs = t.texts_to_sequences(test_data['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 530\n",
    "train_docs = pad_sequences(train_docs, maxlen=max_length, padding='post')\n",
    "valid_docs = pad_sequences(valid_docs, maxlen=max_length, padding='post')\n",
    "test_docs = pad_sequences(test_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 358043 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "        return f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 변수를 초기화합니다.\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 530, 100)          2157500   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 53000)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10000)             530010000 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10000)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               5120512   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 537,353,805\n",
      "Trainable params: 535,196,305\n",
      "Non-trainable params: 2,157,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=530, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10000, input_dim=53000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(512, input_dim=10000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, input_dim=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',F1Score()])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 6s - loss: 0.4695 - accuracy: 0.8003 - f1_score: 0.6429 - 6s/epoch - 29ms/step\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyj/anaconda3/envs/bert/lib/python3.7/site-packages/keras/engine/training.py:2086: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 6s - loss: 0.2554 - accuracy: 0.9008 - f1_score: 0.8336 - 6s/epoch - 27ms/step\n",
      "Epoch 3/3\n",
      "215/215 - 6s - loss: 0.1643 - accuracy: 0.9401 - f1_score: 0.9003 - 6s/epoch - 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1bad028908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(train_docs, train_data['ad_label'], epochs=params['EPOCHS'], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9712 - f1_score: 0.9541\n",
      "Accuracy: 0.971166 F1_Score: 0.954124\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1 = model.evaluate(train_docs, train_data['ad_label'])\n",
    "print('Accuracy: %f' % (accuracy),'F1_Score: %f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 0s - loss: 0.0960 - accuracy: 1.0000 - f1_score: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9138 - f1_score: 0.8619\n",
      "Accuracy: 0.913753 F1_Score: 0.861940\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1 = model.evaluate(valid_docs, valid_data['ad_label'], verbose=1)\n",
    "print('Accuracy: %f' % (accuracy),'F1_Score: %f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.919674 F1_Score: 0.874317\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1 = model.evaluate(test_docs, test_data['ad_label'], verbose=0)\n",
    "print('Accuracy: %f' % (accuracy),'F1_Score: %f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
