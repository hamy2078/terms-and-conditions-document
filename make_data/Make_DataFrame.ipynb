{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "\n",
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xml.etree.ElementTree as et "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    }
   ],
   "source": [
    "def xml_to_csv(xml):\n",
    "    except_list = []\n",
    "    df_cols=[\"category\",\"name\",\"cn\"]\n",
    "    df = pd.DataFrame(columns = df_cols)\n",
    "    cnt = 0\n",
    "    for file in xml:\n",
    "        try:\n",
    "            parser = et.XMLParser(encoding=\"UTF-8\")\n",
    "            xtree = et.parse(file,parser=parser)\n",
    "            xroot = xtree.getroot()\n",
    "            rows=[]\n",
    "\n",
    "            for node in xroot:\n",
    "                s_category=node.find(\"category\").text if node is not None else None\n",
    "                s_name=node.find(\"name\").text if node is not None else None\n",
    "                s_cn=node.find(\"cn\").text if node is not None else None\n",
    "                \n",
    "                rows.append({\"category\":s_category, \"name\":s_name, \"cn\":s_cn})\n",
    "            \n",
    "            out_df = pd.DataFrame(rows,columns=df_cols)\n",
    "            df = pd.concat([df,out_df])\n",
    "        except:\n",
    "            cnt += 1\n",
    "            except_list.append(file)\n",
    "    return df,except_list\n",
    "train_xml_good_list = glob('../Data/Train/Document/01.유리/*.xml')\n",
    "train_xml_bad_list = glob('../Data/Train/Document/02.불리/*.xml')\n",
    "test_xml_good_list = glob('../Data/Test/Document/01.유리/*.xml')\n",
    "test_xml_bad_list = glob('../Data/Test/Document/02.불리/*.xml')\n",
    "\n",
    "train_xml_good_list = sorted(train_xml_good_list)\n",
    "train_xml_bad_list = sorted(train_xml_bad_list)\n",
    "test_xml_good_list = sorted(test_xml_good_list)\n",
    "test_xml_bad_list = sorted(test_xml_bad_list)\n",
    "\n",
    "train_xml_good,trg_list = xml_to_csv(train_xml_good_list)\n",
    "train_xml_bad,trb_list = xml_to_csv(train_xml_bad_list)\n",
    "test_xml_good,teg_list = xml_to_csv(test_xml_good_list)\n",
    "test_xml_bad,teb_list = xml_to_csv(test_xml_bad_list)\n",
    "\n",
    "train_xml_good['ad_label'] = 1\n",
    "train_xml_bad['ad_label'] = 2\n",
    "test_xml_good['ad_label'] = 1\n",
    "test_xml_bad['ad_label'] = 2\n",
    "\n",
    "print(train_xml_good.shape[0]+train_xml_bad.shape[0]+test_xml_good.shape[0]+test_xml_bad.shape[0])\n",
    "\n",
    "train_xml_good.reset_index(inplace=True,drop=True)\n",
    "train_xml_bad.reset_index(inplace=True,drop=True)\n",
    "test_xml_good.reset_index(inplace=True,drop=True)\n",
    "test_xml_bad.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    5600\n",
      "dtype: int64\n",
      "name    2400\n",
      "dtype: int64\n",
      "name    700\n",
      "dtype: int64\n",
      "name    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def xml_name_preprocess(df):\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Train/Document/01.유리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Train/Document/02.불리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Test/Document/01.유리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Test/Document/02.불리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('.xml',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('_가공',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace(' ',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.strip())\n",
    "    return df\n",
    "\n",
    "train_xml_good_name = pd.DataFrame(train_xml_good_list,columns=['name'])\n",
    "train_xml_good_name = xml_name_preprocess(train_xml_good_name)\n",
    "print(train_xml_good_name.nunique())\n",
    "\n",
    "train_xml_bad_name = pd.DataFrame(train_xml_bad_list,columns=['name'])\n",
    "train_xml_bad_name = xml_name_preprocess(train_xml_bad_name)\n",
    "print(train_xml_bad_name.nunique())\n",
    "\n",
    "test_xml_good_name = pd.DataFrame(test_xml_good_list,columns=['name'])\n",
    "test_xml_good_name = xml_name_preprocess(test_xml_good_name)\n",
    "print(test_xml_good_name.nunique())\n",
    "\n",
    "test_xml_bad_name = pd.DataFrame(test_xml_bad_list,columns=['name'])\n",
    "test_xml_bad_name = xml_name_preprocess(test_xml_bad_name)\n",
    "print(test_xml_bad_name.nunique())\n",
    "\n",
    "train_xml_good['name'] = train_xml_good_name['name']\n",
    "train_xml_bad['name'] = train_xml_bad_name['name']\n",
    "test_xml_good['name'] = test_xml_good_name['name']\n",
    "test_xml_bad['name'] = test_xml_bad_name['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_to_csv\n",
    "def json_to_csv(files):\n",
    "    df_cols=[\"clauseArticle\",\"dvAntageous\"]\n",
    "    df = pd.DataFrame(columns = df_cols)\n",
    "        \n",
    "    for file in files:   \n",
    "        with open(file) as f:\n",
    "            json_data = json.load(f)\n",
    "            \n",
    "            clauseArticle = json_data['clauseArticle']\n",
    "            dvAntageous = json_data['dvAntageous']\n",
    "            row = []\n",
    "            row.append({\"clauseArticle\":clauseArticle, \"dvAntageous\":dvAntageous})\n",
    "        out_df = pd.DataFrame(row,columns=df_cols)\n",
    "        df = pd.concat([df,out_df])\n",
    "        \n",
    "    file_name = pd.DataFrame(files)\n",
    "    file_name[0] = file_name[0].apply(lambda x: x.split('/')[-1])\n",
    "    df.reset_index(inplace=True)\n",
    "    df = pd.concat([df,file_name],axis=1)\n",
    "    df.drop(['index'],inplace=True,axis=1)\n",
    "    df.columns = ['clauseArticle','ad_label','name']\n",
    "    return df\n",
    "\n",
    "train_json_good_list = glob('../Data/Train/Label/01.유리/*.json')\n",
    "train_json_bad_list = glob('../Data/Train/Label/02.불리/*.json')\n",
    "test_json_good_list = glob('../Data/Test/Label/01.유리/*.json')\n",
    "test_json_bad_list = glob('../Data/Test/Label/02.불리/*.json')\n",
    "\n",
    "train_json_good_list = sorted(train_json_good_list)\n",
    "train_json_bad_list = sorted(train_json_bad_list)\n",
    "test_json_good_list = sorted(test_json_good_list)\n",
    "test_json_bad_list = sorted(test_json_bad_list)\n",
    "\n",
    "\n",
    "train_json_good = json_to_csv(train_json_good_list)\n",
    "train_json_bad = json_to_csv(train_json_bad_list)\n",
    "test_json_good = json_to_csv(test_json_good_list)\n",
    "test_json_bad = json_to_csv(test_json_bad_list)\n",
    "\n",
    "train_json_good.reset_index(inplace=True,drop=True)\n",
    "train_json_bad.reset_index(inplace=True,drop=True)\n",
    "test_json_good.reset_index(inplace=True,drop=True)\n",
    "test_json_bad.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    5600\n",
      "dtype: int64\n",
      "name    2400\n",
      "dtype: int64\n",
      "name    700\n",
      "dtype: int64\n",
      "name    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def json_name_preprocess(df):\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Train/Label/01.유리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Train/Label/02.불리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Test/Label/01.유리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('../Data/Test/Label/02.불리\\\\',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('_가공.json',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace(' ',''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.strip())\n",
    "    return df\n",
    "\n",
    "train_json_good_name = pd.DataFrame(train_json_good_list,columns=['name'])\n",
    "train_json_good_name = json_name_preprocess(train_json_good_name)\n",
    "print(train_json_good_name.nunique())\n",
    "\n",
    "train_json_bad_name = pd.DataFrame(train_json_bad_list,columns=['name'])\n",
    "train_json_bad_name = json_name_preprocess(train_json_bad_name)\n",
    "print(train_json_bad_name.nunique())\n",
    "\n",
    "test_json_good_name = pd.DataFrame(test_json_good_list,columns=['name'])\n",
    "test_json_good_name = json_name_preprocess(test_json_good_name)\n",
    "print(test_json_good_name.nunique())\n",
    "\n",
    "test_json_bad_name = pd.DataFrame(test_json_bad_list,columns=['name'])\n",
    "test_json_bad_name = json_name_preprocess(test_json_bad_name)\n",
    "print(test_json_bad_name.nunique())\n",
    "\n",
    "train_json_good['name'] = train_json_good_name['name']\n",
    "train_json_bad['name'] = train_json_bad_name['name']\n",
    "test_json_good['name'] = test_json_good_name['name']\n",
    "test_json_bad['name'] = test_json_bad_name['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 5)\n",
      "(2400, 5)\n",
      "(700, 5)\n",
      "(300, 5)\n"
     ]
    }
   ],
   "source": [
    "train_json_good['ad_label'] = train_json_good['ad_label'].apply(lambda x: int(x))\n",
    "train_json_bad['ad_label'] = train_json_bad['ad_label'].apply(lambda x: int(x))\n",
    "test_json_good['ad_label'] = test_json_good['ad_label'].apply(lambda x: int(x))\n",
    "test_json_bad['ad_label'] = test_json_bad['ad_label'].apply(lambda x: int(x))\n",
    "\n",
    "train_good = pd.merge(train_xml_good,train_json_good,on=['name','ad_label'],how='inner')\n",
    "train_bad = pd.merge(train_xml_bad,train_json_bad,on=['name','ad_label'],how='inner')\n",
    "test_good = pd.merge(test_xml_good,test_json_good,on=['name','ad_label'],how='inner')\n",
    "test_bad = pd.merge(test_xml_bad,test_json_bad,on=['name','ad_label'],how='inner')\n",
    "print(train_good.shape)\n",
    "print(train_bad.shape)\n",
    "print(test_good.shape)\n",
    "print(test_bad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_good,train_bad,test_good,test_bad])\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df = df[['category','name','ad_label','cn','clauseArticle']]\n",
    "df.columns = ['category','name','ad_label','cn','summary']\n",
    "\n",
    "df['category'] = df['category'].apply(lambda x: x.replace('\\n',''))\n",
    "df['category'] = df['category'].apply(lambda x: x.replace('\\t',''))\n",
    "df['category'] = df['category'].apply(lambda x: x.replace('.pdf',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>ad_label</th>\n",
       "      <th>cn</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24. 개인정보취급방침</td>\n",
       "      <td>001_개인정보취급방침</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\n\\n\\n\\n\\n\\n제 1 조 개인정보의 처리 목적\\n회사는 다음의 목...</td>\n",
       "      <td>[제2조(개인정보의 처리 및 보유기간) \\n① 협회는 법령에 따른 개인정보 보유․이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27. 결혼정보서비스</td>\n",
       "      <td>001_결혼정보서비스</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\n\\n\\n000 \\n\\n \\n\\n제1조(목적 등)  \\n\\n1. 본 약...</td>\n",
       "      <td>[제3조 (회원가입)\\n① 회원이 되려고 하는 사람은 결혼관련 개인정보를 회사에 제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.보증</td>\n",
       "      <td>001_보증</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\n\\n \\n\\n \\n \\n\\n신용보증약정서 \\n \\n\\n000 귀중\\n...</td>\n",
       "      <td>[제2조(보증금액)\\n ① 이 보증서에 의한 보증금액은 채권자의 채무자에 대한 보증...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31. 사이버몰</td>\n",
       "      <td>001_사이버몰</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\n\\n \\n제1조(목적) \\n이 약관은 000 회사(전자상거래 사업자)...</td>\n",
       "      <td>[제3조 (약관 등의 명시와 설명 및 개정)\\n① 몰은 이 약관의 내용과 상호 및 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12. 상해보험</td>\n",
       "      <td>001_상해보험</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\n\\n \\n\\n00000 \\n\\n약관 \\n \\n\\n제1관  목적  및 ...</td>\n",
       "      <td>[제4조(보험금 지급에 관한 세부규정)\\n② 제3조(보험금의 지급사유) 제2호에서 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category          name  ad_label  \\\n",
       "0  24. 개인정보취급방침  001_개인정보취급방침         1   \n",
       "1   27. 결혼정보서비스   001_결혼정보서비스         1   \n",
       "2         30.보증        001_보증         1   \n",
       "3      31. 사이버몰      001_사이버몰         1   \n",
       "4      12. 상해보험      001_상해보험         1   \n",
       "\n",
       "                                                  cn  \\\n",
       "0  \\n\\t\\t\\n\\n\\n\\n\\n\\n제 1 조 개인정보의 처리 목적\\n회사는 다음의 목...   \n",
       "1  \\n\\t\\t\\n\\n\\n000 \\n\\n \\n\\n제1조(목적 등)  \\n\\n1. 본 약...   \n",
       "2  \\n\\t\\t\\n\\n \\n\\n \\n \\n\\n신용보증약정서 \\n \\n\\n000 귀중\\n...   \n",
       "3  \\n\\t\\t\\n\\n \\n제1조(목적) \\n이 약관은 000 회사(전자상거래 사업자)...   \n",
       "4  \\n\\t\\t\\n\\n \\n\\n00000 \\n\\n약관 \\n \\n\\n제1관  목적  및 ...   \n",
       "\n",
       "                                             summary  \n",
       "0  [제2조(개인정보의 처리 및 보유기간) \\n① 협회는 법령에 따른 개인정보 보유․이...  \n",
       "1  [제3조 (회원가입)\\n① 회원이 되려고 하는 사람은 결혼관련 개인정보를 회사에 제...  \n",
       "2  [제2조(보증금액)\\n ① 이 보증서에 의한 보증금액은 채권자의 채무자에 대한 보증...  \n",
       "3  [제3조 (약관 등의 명시와 설명 및 개정)\\n① 몰은 이 약관의 내용과 상호 및 ...  \n",
       "4  [제4조(보험금 지급에 관한 세부규정)\\n② 제3조(보험금의 지급사유) 제2호에서 ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./preprocessed_data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
