{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyj/anaconda3/envs/bert/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from model import DNN\n",
    "from dataloader import DNNDataset\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'EPOCHS':2,\n",
    "    'LEARNING_RATE':1e-7,\n",
    "    'BATCH_SIZE':128,\n",
    "    'SEED':45,\n",
    "    'MAX_FEATURES': 15000,\n",
    "    'TRAIN_DATA_PATH': '../../make_data/preprocessed_data/article_train.csv',\n",
    "    'VALID_DATA_PATH': '../../make_data/preprocessed_data/article_valid.csv',\n",
    "    'TEST_DATA_PATH': '../../make_data/preprocessed_data/article_test.csv',\n",
    "    'SAVE_PATH':'../Models/TF-IDF_Article.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(params['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fc48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(params['TRAIN_DATA_PATH'],index_col=[0])\n",
    "valid_data = pd.read_csv(params['VALID_DATA_PATH'],index_col=[0])\n",
    "test_data = pd.read_csv(params['TEST_DATA_PATH'],index_col=[0])\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "valid_data = valid_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22defed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True,inplace=True)\n",
    "valid_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e8ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64591\n",
      "64591\n",
      "11851\n",
      "11851\n",
      "15123\n",
      "15123\n",
      "0    0.91889\n",
      "1    0.08111\n",
      "Name: label, dtype: float64\n",
      "0    0.944562\n",
      "1    0.055438\n",
      "Name: label, dtype: float64\n",
      "0    0.956292\n",
      "1    0.043708\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_data.drop_duplicates(['sent_jo'])))\n",
    "\n",
    "print(len(valid_data))\n",
    "print(len(valid_data.drop_duplicates(['sent_jo'])))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_data.drop_duplicates(['sent_jo'])))\n",
    "\n",
    "print(train_data['label'].value_counts()/len(train_data))\n",
    "print(valid_data['label'].value_counts()/len(valid_data))\n",
    "print(test_data['label'].value_counts()/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d3a3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=15000, ngram_range=(1, 2), sublinear_tf=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 2), max_features=params['MAX_FEATURES'], binary=False)\n",
    "tfidf.fit(train_data['sent_jo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5165289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DNNDataset(train_data,tfidf)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=params['BATCH_SIZE'])\n",
    "\n",
    "valid_dataset = DNNDataset(valid_data,tfidf)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=params['BATCH_SIZE'])\n",
    "\n",
    "test_dataset = DNNDataset(test_data,tfidf)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=params['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8825aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,valid_loader, device):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=1e-3)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = \"None\"\n",
    "    for epoch_num in range(1,params[\"EPOCHS\"]+1):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = []\n",
    "        for data in tqdm(train_loader):\n",
    "            \n",
    "            train_texts = data['text']\n",
    "            train_labels = data['label']\n",
    "            train_label = train_labels.to(device)\n",
    "            train_text = train_texts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(train_text)  \n",
    "            \n",
    "            output = output.reshape(-1)\n",
    "            batch_loss = criterion(output.to(torch.float32), train_label.to(torch.float32)) \n",
    "            train_loss.append(batch_loss.item())\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss, val_acc, val_f1 = validation(model, criterion, valid_loader, device)\n",
    "        print(f'Epoch [{epoch_num}], Train Loss : [{np.mean(train_loss) :.5f}] \\\n",
    "              Val Loss : [{np.mean(val_loss) :.5f}] Val Accuracy Score : [{val_acc:.5f}] Val F1 Score : [{val_f1:.5f}]')\n",
    "        \n",
    "        val_score = val_f1\n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc62d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return accuracy_score(true,pred),f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation(model,criterion,valid_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    model_preds = []\n",
    "    true_labels = []  \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader):\n",
    "            \n",
    "            valid_texts = data['text']\n",
    "            valid_labels = data['label']\n",
    "          \n",
    "            valid_label = valid_labels.to(device)\n",
    "            valid_text = valid_texts.to(device)\n",
    "\n",
    "            output = model(valid_text)    \n",
    "            \n",
    "            output = output.reshape(-1)\n",
    "            batch_loss = criterion(output.to(torch.float32), valid_label.to(torch.float32)) \n",
    "            val_loss.append(batch_loss.item())\n",
    "            \n",
    "            output[output>0.5] = 1\n",
    "            output[output<=0.5] = 0\n",
    "            model_preds += output.detach().cpu().numpy().tolist()\n",
    "            true_labels += valid_label.detach().cpu().numpy().tolist()\n",
    "        val_acc, val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return val_loss, val_acc, val_f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cddaf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            \n",
    "            test_texts = data['text']\n",
    "            test_text = test_texts.to(device)\n",
    "\n",
    "            output = model(test_text)    \n",
    "            \n",
    "            output[output>0.5] = 1\n",
    "            output[output<=0.5] = 0\n",
    "            test_predict += output.detach().cpu().numpy().tolist()\n",
    "    test_predict = torch.Tensor(test_predict)\n",
    "    test_predict = test_predict.reshape(-1)\n",
    "    print('Done.')\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b624963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:12<00:00, 41.13it/s]\n",
      "100%|██████████| 93/93 [00:01<00:00, 75.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.17303]               Val Loss : [0.11328] Val Accuracy Score : [0.96692] Val F1 Score : [0.82205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:11<00:00, 42.91it/s]\n",
      "100%|██████████| 93/93 [00:01<00:00, 75.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.10872]               Val Loss : [0.12044] Val Accuracy Score : [0.96253] Val F1 Score : [0.81747]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.eval()\n",
    "\n",
    "infer_model = train(model, train_dataloader, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a1a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 75.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(0.9611188256298353, 0.779508223061707)\n",
      "[[14130   332]\n",
      " [  256   405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_labels = test_data['label']\n",
    "test_preds = inference(infer_model,test_dataloader,device)\n",
    "\n",
    "print(competition_metric(test_labels,test_preds))\n",
    "\n",
    "print(confusion_matrix(test_labels,test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44565023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:06<00:00, 73.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(0.9682927962099983, 0.8845489174446675)\n",
      "[[58777   575]\n",
      " [ 1473  3766]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = train_data['label']\n",
    "preds = inference(infer_model,train_dataloader,device)\n",
    "\n",
    "print(competition_metric(labels,preds))\n",
    "\n",
    "print(confusion_matrix(labels,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd9b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:01<00:00, 74.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(0.9625348071892668, 0.8174680549218898)\n",
      "[[10986   208]\n",
      " [  236   421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = valid_data['label']\n",
    "preds = inference(infer_model,valid_dataloader,device)\n",
    "\n",
    "print(competition_metric(labels,preds))\n",
    "\n",
    "print(confusion_matrix(labels,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db59c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infer_model.state_dict(),params['SAVE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ac059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da1327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
